# Docker Environment Configuration
ENVIRONMENT=development

# API Configuration
API_HOST=0.0.0.0
API_PORT=44101

# LLM Service Configuration (Docker internal networking)
LLM_BASE_URL=http://ollama:11434
LLM_MODEL=tinyllama
LLM_TIMEOUT=30.0
LLM_MAX_RETRIES=3
LLM_TEMPERATURE=0.7

# Logging
LOG_LEVEL=DEBUG

# Service Configuration
SERVICE_NAME=text-similarity-service
VERSION=1.0.0
